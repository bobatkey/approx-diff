\section{Formal Structures for Generalised Automatic Differentiation}

\subsection{Category of lattices and Galois connections}

First we introduce the category of lattices and Galois connections, which will serve as our base category for
interpreting forward and backward Galois slicing. Galois connections are pairs of monotone functions $f: Y \to
X$ and $g: X \to Y$ between posets, where $f$ is the (pointwise) best approximation from below to an inverse
of $g$, and $g$ the best approximation from above to an inverse of $f$.

\begin{definition}[Galois connection]
Suppose $X$ and $Y$ are posets. A \emph{Galois connection} $f \adj g: X \to Y$ is a pair of monotone functions
$f: Y \to X$ and $g: X \to Y$ satisfying $y \leq f(x) \iff g(y) \leq x$ for any $x \in X$ and $y \in Y$.
\end{definition}

\noindent Galois connections thus generalise order isomorphisms. The $\adj$ notation is justified because a
Galois connection $f \adj g: X \to Y$ can also be seen an adjunction between poset categories, with monotone
$f$ and $g$ interpreted as functors; $f$ is usually referred to as the \emph{upper} (right) adjoint and $g$ as
the \emph{lower} (left) adjoint. Galois connections compose component-wise, with $\id_X \adj \id_X: X \to X$
as the unit for composition, and thus form a category $\PosGal$ with all posets as objects and all Galois
connections between them as morphisms.

As sketched in \secref{introduction:galois-slicing}, Galois slicing requires the approximants of a point $x$
to form a bounded lattice $(X, \meet, \join, \top, \bot)$, with least element $\bot$ representing the
approximation that discards all information about $x$, greatest element $\top$ representing the approximation
that retains all information about $x$, and $\meet$ and $\join$ providing two canonical ways to combine
approximations. Thus rather than working in $\PosGal$, we define the following subcategory.

\begin{definition}
Define the category $\LatGal$ which has as objects $X = (X, \meet, \join, \top, \bot)$ all bounded lattices,
and as morphisms all Galois connections $f \adj g: X \to Y$.
\end{definition}

\noindent Right adjoints preserves limits and left adjoints preserves colimits, so for any $f \adj g: X \to Y$
in $\LatGal$, $f$ is a \emph{meet-semilattice homomorphism}, i.e.~preserves the meet-semilattice structure
$(X, \meet, \top)$. Similarly, $g$ is a join-semilattice homomorphism with respect to $(X, \join, \bot)$.

\subsubsection{Additive structure on morphisms.}

A bounded semilattice is an example of a \emph{commutative monoid} $(X, +, 0)$, namely a set $X$ equipped with
an associative, commutative binary operation $+$ with unit $0$. One observation about commutative monoids is
that pointwise lifting of $+$ to homomorphisms $f, g: X \to Y$, where $(f + g)(x) = f(x) + g(x): X \to Y$, is
also ``additive'', in the sense of being associative and commutative and having a ``zero'' homomorphism
$0_{X,Y}: X \to Y$ given by the constant map sending any $x \in X$ to $0_Y$, which acts as a unit for addition
of homomorphisms. The homomorphisms from $X$ to $Y$ thus have a commutative monoid structure themselves.

In particular $\LatGal$ has this structure..

% Moreover since $(X, \top, \meet)$ is a commutative monoid, and thus a $\CMon$-enriched (poset)
% category, for any $X, Y$ there is a zero meet-semilattice homomorphism $0^{\meet}_{X,Y} = \const(\top_Y): X
% \to Y$ and also (idempotent) addition of homomorphisms $f +_{\meet} g: X \to Y$ given pointwise by $\meet$.
% Dually, there is a zero join-semilattice homomorphism $0^{\join}_{X,Y} = \const(\bot_Y): X \to Y$ and
% idempotent addition of homomorphisms $f +_{\join} g: X \to Y$ given pointwise by $\join$.

\subsection{Biproducts and Semi-Additive Categories}

\begin{definition}[Semi-additive category]
A category with finite products and coproducts is \emph{semi-additive} if the canonical morphisms (projections
and injections) give an isomorphism
\[\textstyle X \coprod Y \iso X \prod Y\] that is natural in both variables.
\end{definition}

The product/coproduct is called a \emph{biproduct}, and the biproduct structure is denoted by $(\biprod, 0)$.
The unit $0$ is both terminal and initial and is called a \emph{zero} object. \todo{State biproduct ``laws''
that follow from this formulation.} A semi-additive category $\cat{C}$ is enriched in $\CMon$, the category of
commutative monoids: for any two morphisms $f, g: X \to Y$ in $\cat{C}$, the biproduct structure provides a
way to ``add'' them together, forming a morphism $f + g: X \to Y$. Diagrammatically:

\vspace{-2mm}
\begin{center}
\begin{tikzcd}
   X \arrow[r, "\diag"] & X \biprod X \arrow[r, "f \biprod g"] & Y \biprod Y \arrow[r, "\codiag"] & Y
\end{tikzcd}
\end{center}

Here $\diag$ denotes the diagonal $\prodM{\id_X}{\id_X}$ given by the universal property of the product and
$\codiag$ denotes the codiagonal $\coprodM{\id_X}{\id_Y}$ given by the universal property of the coproduct.
The $f \oplus g$ morphism is the component-wise map $\prodM{f \comp \pi_1}{g \comp \pi_2} = \coprodM{\inj_1
\comp f}{\inj_2 \comp g}$. Similarly we can exhibit a \emph{zero} morphism $0_{X,Y}$ by composing the unique
maps in and out of the zero object:

\begin{center}
\begin{tikzcd}
   X \arrow[r, "!_X"] & 0 \arrow[r, "!^Y"] & Y
\end{tikzcd}
\end{center}

It is easy to verify that $+$ is associative and commutative and that $f + 0_{X,Y} = f$, and thus that every
hom-object $\cat{C}(X,Y)$ is an object in $\CMon$. Moreover composition is \emph{bilinear}, i.e.~given by a
family of morphisms $\Hom{\cat{C}}{Y}{Z} \tensor \Hom{\cat{C}}{X}{Y} \to \Hom{\cat{C}}{X}{Z}$ in $\CMon$ that
preserve the additive structure in $\Hom{\cat{C}}{Y}{Z}$ and $\Hom{\cat{C}}{X}{Y}$ separately:

\begin{salign*}
f \comp \zero_{X,Y} = 0_{X,Z} = \zero_{Y,Z} \comp f
\end{salign*}
\begin{salign*}
(f + g) \comp h &= (f \comp h) + (g \comp h) \\
h \comp (f + g) &= (h \comp f) + (h \comp g)
\end{salign*}

% Done:
% (1) introduce the category of lattices and Galois connections, which is what we will use to interpret forward and backward approximation, and establish some properties of this category;

\note{Probably a better way: (2) say that we want sets with each point having an associated lattice of approximations, and morphisms to match; (3) note that this is exactly the Grothendieck construction for a particular indexed category; (4) Say that CHAD is what we need here; (5) Recapitulate the bits of CHAD that we need, with our Agda formalisation; (6) Explain how we cope with higher-order structure, by using presheaves and the Yoneda embedding.}

We take an approach based on the CHAD (Combinatory Homomorphic Automatic Differentiation) of Mattias Vákár and others \cite{nunes2023}. Here follows a rough overview of this approach and how we have applied it to Galois program slicing. \todo{Final version shouldn't be ``rough''!}

We have \href{https://github.com/bobatkey/approx-diff}{formalised this work in Agda}. Not only does this mean that the constructions and proofs have been checked, the construction is executable and can be run on small examples. We are also planning to use Agda's JavaScript backend to produce a demo.\todo{Do this?}

The fundamental approach in CHAD is to consider Grothendieck constructions on indexed categories $T : \cat{C}^\op \to \Cat$. An object of the Grothendieck construction $\int T$ is a pair $(X \in \cat{C}, \partial X \in T(X))$, which we read as pairing a space $X$ of ``points'' from $\cat{C}$ with an associated bundle of tangent spaces. The maps from the ``base'' category $\cat{C}$ are used to interpret the programs we are modelling. The maps in the indexed category are the maps of tangents or approximations, being derivatives and Galois connections respectively.

In the case of differentiable programs and automatic differentiation, a basic model can be constructed by taking $\cat{C}$ to be $\Set$ and $T(X) = X \to \FinVect$: indexed collections of finite dimensional vector spaces, whose elements are interpreted as tangents at the given point, with linear maps. The Grothendieck category $\int T$ has objects that are pairs of a set $X$ and for each $x \in X$ a tangent vector space $\partial X(x)$. Morphisms are pairs of maps of points to points, accompanied by linear maps of tangents at those points. If we carefully choose an initial set of maps, we can read these maps as derivatives (note that nothing in the Grothendieck construction says that they must be derivatives!). Composition in the Grothendieck category is exactly the {\em chain rule} for composing derivatives, so we at least do know that if we start with derivatives on basic operations, then composing them will retain this property.

For Galois program slicing, we again take $\cat{C}$ to be $\Set$ and now take $T(X) = X \to \LatGal$: indexed collections of lattices, whose elements are interpreted as approximations at the given point, with indexed Galois connections as the maps between them.

In these special cases when $\cat{C} = \Set$, the Grothendieck construction is the {\em families} constructions $\Fam(\FinVect)$ and $\Fam(\LatGal)$. As is well known~\cite{lawvere63}, $\Fam(\cat{X})$ for any category $\cat{X}$ is the free coproduct completion of $\cat{X}$. In the case that $\cat{X}$ has a (symmetric) monoidal product, then we always get a symmetric monoidal product on $\Fam(\cat{X})$ (using the Cartesian products from $\Set$). When $\cat{X}$ has all (small) products, and the monoidal product is actually a coproduct, then $\Fam(\cat{X})$ is symmetric monoidal closed. If the coproducts are actually {\em biproducts}, then $\Fam(\cat{X})$ is Cartesian closed, and we can interpret higher-order programs.

\todo{Preceeding paragraph needs references to later in the document where these constructions are detailed in full.}

Happily, $\FinVect$ and $\LatGal$ both have biproducts, as a consequence of them having products and being enriched in commutative monoids\todo{fwd ref}. However, neither of them has all small products, without moving to infinite dimensional vector spaces (in the case of $\FinVect$) or complete lattices (in the case of $\LatGal$). Neither of these are ideal. In infinite dimensional vector spaces, dualisation is not involutive and the connection between the forward and reverse derivatives is lost. In complete lattices, we can no longer easily implement the infinite meets and joins required, and we lose the computability of the model. Moreover, in Agda, there are issues with predicativity when considering complete lattices.\todo{be more specific}

Vákár overcomes this by using different interpretations for forward and backward derivatives. we overcome this by using $\CMon$-enriched presheaves.\todo{elaborate.}
