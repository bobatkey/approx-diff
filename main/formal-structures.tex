\section{Formal Structures for Generalised Automatic Differentiation}

\begin{definition}[Biproducts and Semi-additive categories]
A category with finite products and coproducts is \emph{semi-additive} if the canonical morphisms (projections
and inclusions) give an isomorphism
\[\textstyle X \coprod Y \iso X \prod Y\] that is natural in both variables. The product/coproduct is called a
\emph{biproduct}, and the biproduct structure is denoted by $(\biprod, 0)$. The unit $0$ is both terminal and
initial and is called a \emph{zero} object.
\end{definition}

A semi-additive category $\cat{C}$ is enriched in $\CMon$, the category of commutative monoids: for any two
morphisms $f, g: X \to Y$ in $\cat{C}$, the biproduct structure provides a way to ``add'' them together,
forming a morphism $f + g: X \to Y$. Diagrammatically:

\begin{center}
\begin{tikzcd}
   X \arrow[r, "\diag"] & X \biprod X \arrow[r, "f \biprod g"] & Y \biprod Y \arrow[r, "\codiag"] & Y
\end{tikzcd}
\end{center}

\noindent Here $\diag$ denotes the diagonal $\prodM{\id_X}{\id_X}$ given by the universal property of the
product and $\codiag$ denotes the codiagonal $\coprodM{\id_X}{\id_Y}$ given by the universal property of the
coproduct. The $f \oplus g$ morphism is the component-wise map $\prodM{f}{g} = \coprodM{f}{g}$. Similarly we
can define a \emph{zero} morphism $0_{X,Y}$ by composing the unique maps in and out of the zero object:

\begin{center}
\begin{tikzcd}
   X \arrow[r, "!_X"] & 0 \arrow[r, "!^Y"] & Y
\end{tikzcd}
\end{center}

\note{Probably a better way: (1) introduce the category of lattices and Galois connections, which is what we will use to interpret forward and backward approximation, and establish some properties of this category; (2) say that we want sets with each point having an associated lattice of approximations, and morphisms to match; (3) note that this is exactly the Grothendieck construction for a particular indexed category; (4) Say that CHAD is what we need here; (5) Recapitulate the bits of CHAD that we need, with our Agda formalisation; (6) Explain how we cope with higher-order structure, by using presheaves and the Yoneda embedding.}

We take an approach based on the CHAD (Combinatory Homomorphic Automatic Differentiation) of Mattias V치k치r and others \cite{nunes2023}. Here follows a rough overview of this approach and how we have applied it to Galois program slicing. \todo{Final version shouldn't be ``rough''!}

We have \href{https://github.com/bobatkey/approx-diff}{formalised this work in Agda}. Not only does this mean that the constructions and proofs have been checked, the construction is executable and can be run on small examples. We are also planning to use Agda's JavaScript backend to produce a demo.\todo{Do this?}

The fundamental approach in CHAD is to consider Grothendieck constructions on indexed categories $T : \cat{C}^\op \to \Cat$. An object of the Grothendieck construction $\int T$ is a pair $(X \in \cat{C}, \partial X \in T(X))$, which we read as pairing a space $X$ of ``points'' from $\cat{C}$ with an associated bundle of tangent spaces. The maps from the ``base'' category $\cat{C}$ are used to interpret the programs we are modelling. The maps in the indexed category are the maps of tangents or approximations, being derivatives and Galois connections respectively.

In the case of differentiable programs and automatic differentiation, a basic model can be constructed by taking $\cat{C}$ to be $\Set$ and $T(X) = X \to \FinVect$: indexed collections of finite dimensional vector spaces, whose elements are interpreted as tangents at the given point, with linear maps. The Grothendieck category $\int T$ has objects that are pairs of a set $X$ and for each $x \in X$ a tangent vector space $\partial X(x)$. Morphisms are pairs of maps of points to points, accompanied by linear maps of tangents at those points. If we carefully choose an initial set of maps, we can read these maps as derivatives (note that nothing in the Grothendieck construction says that they must be derivatives!). Composition in the Grothendieck category is exactly the {\em chain rule} for composing derivatives, so we at least do know that if we start with derivatives on basic operations, then composing them will retain this property.

For Galois program slicing, we again take $\cat{C}$ to be $\Set$ and now take $T(X) = X \to \LatGal$: indexed collections of lattices, whose elements are interpreted as approximations at the given point, with indexed Galois connections as the maps between them.

In these special cases when $\cat{C} = \Set$, the Grothendieck construction is the {\em families} constructions $\Fam(\FinVect)$ and $\Fam(\LatGal)$. As is well known~\cite{lawvere63}, $\Fam(\cat{X})$ for any category $\cat{X}$ is the free coproduct completion of $\cat{X}$. In the case that $\cat{X}$ has a (symmetric) monoidal product, then we always get a symmetric monoidal product on $\Fam(\cat{X})$ (using the Cartesian products from $\Set$). When $\cat{X}$ has all (small) products, and the monoidal product is actually a coproduct, then $\Fam(\cat{X})$ is symmetric monoidal closed. If the coproducts are actually {\em biproducts}, then $\Fam(\cat{X})$ is Cartesian closed, and we can interpret higher-order programs.

\todo{Preceeding paragraph needs references to later in the document where these constructions are detailed in full.}

Happily, $\FinVect$ and $\LatGal$ both have biproducts, as a consequence of them having products and being enriched in commutative monoids\todo{fwd ref}. However, neither of them has all small products, without moving to infinite dimensional vector spaces (in the case of $\FinVect$) or complete lattices (in the case of $\LatGal$). Neither of these are ideal. In infinite dimensional vector spaces, dualisation is not involutive and the connection between the forward and reverse derivatives is lost. In complete lattices, we can no longer easily implement the infinite meets and joins required, and we lose the computability of the model. Moreover, in Agda, there are issues with predicativity when considering complete lattices.\todo{be more specific}

V치k치r overcomes this by using different interpretations for forward and backward derivatives. we overcome this by using $\CMon$-enriched presheaves.\todo{elaborate.}
