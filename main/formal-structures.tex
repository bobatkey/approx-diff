\section{Formal Structures for Generalised Automatic Differentiation}

Our approach to a denotational account of \GPS is based on the CHAD (Combinatory Homomorphic Automatic Differentiation) work of Mattias Vákár and others~\cite{vákár22,nunes2023}. Before we go into details, we present a high-level overview of their approach and how we have applied it to \GPS.

The fundamental approach in CHAD is to consider Grothendieck constructions on indexed categories $T : \cat{C}^\op \to \Cat$. An object of the Grothendieck construction $\int T$, described in more detail in \secref{Grothendieck}, is a pair $(X \in \cat{C}, \partial X \in T(X))$, which we read as pairing a space $X$ of ``points'' from $\cat{C}$ with an associated bundle of tangent spaces. The maps from the ``base'' category $\cat{C}$ are used to interpret the programs we are modelling. The maps in the indexed category are the maps of tangents or approximations, being derivatives and Galois connections respectively.

In the case of differentiable programs and automatic differentiation, a basic model can be constructed by taking $\cat{C}$ to be $\Set$ and $T(X) = X \to \FinVect$: indexed collections of finite dimensional vector spaces, whose elements are interpreted as tangents at the given point, with linear maps. The Grothendieck category $\int T$ has objects that are pairs of a set $X$ and for each $x \in X$ a tangent vector space $\partial X(x)$. Morphisms are pairs of maps of points to points, accompanied by linear maps of tangents at those points. If we carefully choose an initial set of maps, we can read these maps as derivatives (note that nothing in the Grothendieck construction says that they must be derivatives!). Composition in the Grothendieck category is exactly the {\em chain rule} for composing derivatives, so we at least do know that if we start with derivatives on basic operations, then composing them will retain this property.

For \GPS, we again take $\cat{C}$ to be $\Set$ and now take $T(X) = X \to \LatGal$: indexed collections of lattices, whose elements are interpreted as approximations at the given point, with indexed Galois connections as the maps between them.

In these special cases when $\cat{C} = \Set$, the Grothendieck construction is the {\em families} constructions $\Fam(\FinVect)$ and $\Fam(\LatGal)$~(\secref{Fam}). These settings are adequate for interpreting first-order programs, but neither is Cartesian closed. The picture for higher-order programs is more complicated. As is well known, $\Fam(\cat{X})$ for any category $\cat{X}$ is the free coproduct completion of $\cat{X}$~\cite{lawvere63}. In the case that $\cat{X}$ has a (symmetric) monoidal product, then we always get a symmetric monoidal product on $\Fam(\cat{X})$, using the Cartesian products from $\Set$. When $\cat{X}$ has all (small) products, and the monoidal product is actually a coproduct, then $\Fam(\cat{X})$ is symmetric monoidal closed. If the coproducts are actually {\em biproducts}~(\secref{biproducts}), then $\Fam(\cat{X})$ is Cartesian closed, and we can interpret higher-order programs.

Happily, $\FinVect$ and $\LatGal$ both have biproducts, as a consequence of their having products and being enriched in commutative monoids~(\propref{biproducts:from-product-or-coproduct} below). However, neither of them has all small products, without moving to infinite dimensional vector spaces (in the case of $\FinVect$) or complete lattices (in the case of $\LatGal$). Neither of these are ideal. In infinite dimensional vector spaces, dualisation is not involutive and the connection between the forward and reverse derivatives is lost. In complete lattices, we can no longer easily implement the infinite meets and joins required, and we lose the computability of the model. Moreover, in Agda, there are issues with predicativity when considering complete lattices. \todo{be more specific}

Vákár and collaborators overcome this by using different interpretations for forward and backward derivatives. We overcome this by using $\CMon$-enriched presheaves; we turn to this in \secref{higher-order} but first flesh out the first-order setting.

\subsection{Category of Lattices and Galois Connections}

First we introduce the category of lattices and Galois connections, which will serve as our base category for
interpreting forward and backward \GPS. Galois connections are pairs of monotone functions $f: Y \to
X$ and $g: X \to Y$ between posets, where $f$ is the (pointwise) best approximation from below to an inverse
of $g$, and $g$ the best approximation from above to an inverse of $f$. This setup is a nice fit for the
bidirectional nature of (dynamic) program slicing, with $f$ capturing \emph{backward} slicing (producing the
least input slice for a given slice of the output), and $g$ capturing \emph{forward} slicing (producing the
greatest output slice for a given slice of the input).

\begin{definition}[Galois connection]
Suppose $X$ and $Y$ are posets. A \emph{Galois connection} $f \adj g: X \to Y$ is a pair of monotone functions
$f: Y \to X$ and $g: X \to Y$ satisfying $y \leq g(x) \iff f(y) \leq x$ for any $x \in X$ and $y \in Y$.
\end{definition}

\noindent Galois connections thus generalise order isomorphisms. The $\adj$ notation is justified because a
Galois connection $f \adj g: X \to Y$ can also be seen an adjunction between poset categories, with monotone
$f$ and $g$ regarded as functors; $f$ is usually referred to as the \emph{upper} (right) adjoint and $g$ as
the \emph{lower} (left) adjoint. Galois connections compose component-wise, with $\id_X \adj \id_X: X \to X$
as the unit for composition, and thus form a category $\PosGal$ with all posets as objects and all Galois
connections between them as morphisms.

As sketched in \secref{introduction:galois-slicing}, for \GPS we would like a setting where the approximants
of a point $x$ form a bounded lattice $(X, \meet, \join, \top, \bot)$, with least element $\bot$ representing
the approximation that discards all information about $x$, greatest element $\top$ representing the
approximation that retains all information about $x$, and $\meet$ and $\join$ providing two canonical ways to
combine approximations. Thus rather than working directly in $\PosGal$, we consider the following subcategory
instead.

\begin{definition}
Define $\LatGal$ to be the category which has as objects $X = (X, \meet, \join, \top, \bot)$ all bounded
lattices, and as morphisms all Galois connections $f \adj g: X \to Y$.
\end{definition}

\noindent Right adjoints preserves limits and left adjoints preserves colimits, so for any $f \adj g: X \to Y$
in $\LatGal$, $g$ is a (bounded) \emph{meet-semilattice homomorphism}, i.e.~preserves the meet-semilattice
structure $(X, \meet, \top)$. Similarly, $f$ is a join-semilattice homomorphism with respect to $(X, \join,
\bot)$.

The meet-preserving maps from $X$ to $Y$ themselves form a meet-semilattice. The operation $\meet$ on such
maps is defined pointwise, so that $(f \meet g)(x) = f(x) \meet g(x): X \to Y$, and preserves meets; the
constant map $\top_{X,Y}: X \to Y$ sending any $x \in X$ to $\top_Y$, which also preserves meets, provides the
unit. Dually the join-preserving maps from $Y$ to $X$ have a join-semilattice structure given pointwise by
$\join$ and the constant homomorphism $\bot_{Y,X}: Y \to X$ sending any $y \in Y$ to $\bot_X$. Since these two
constructions come in adjoint pairs, the hom-set $\LatGal(X,Y)$ forms a bounded meet semilattice with unit
$\top_{X,Y}$ given by the Galois connection $\bot_{Y,X} \adj \top_{X,Y}: X \to Y$ and meet of Galois
connections $(f \adj g) \meet (f' \adj g') = (f \join f') \adj (g \meet g'): X \to Y$. Thus $\LatGal$ is
enriched in $\SemiLat$, the category of semilattices and semilattice homomorphisms.

$\LatGal$ is not Cartesian closed, and so we cannot use it directly to interpret higher-order programs. In
fact Cartesian closure is incompatible with another notable property of $\LatGal$, which follows from the fact
that the projections $\pi_1: X \times Y \to X$ and $\pi_2: X \times Y \to Y$, where $X \times Y$ denotes the
product of lattices, have both upper and lower adjoints. This allows $X \times Y$, which we shall hereafter
write as $X \biprod Y$, to act as both a product and a coproduct, with projections $\biproj_X$ and $\biproj_Y$
and injections $\biinj_X$ and $\biinj_Y$ given by:

\vspace{-4mm}
\begin{minipage}[t]{0.45\textwidth}
\begin{center}
\begin{align*}
   \biproj_X = \prodM{\id_X}{\bot_Y} \adj \proj_1: X \biprod Y \to X \\
   \biproj_Y = \prodM{\bot_X}{\id_Y} \adj \proj_2: X \biprod Y \to Y
\end{align*}
\end{center}
\end{minipage}%
\begin{minipage}[t]{0.45\textwidth}
\begin{center}
\begin{align*}
   \biinj_X = \pi_1 \adj \prodM{\id_X}{\top_Y} : X \to X \biprod Y \\
   \biinj_Y = \pi_2 \adj \prodM{\top_X}{\id_Y}: Y \to X \biprod Y
\end{align*}
\end{center}
\end{minipage}
\vspace{2mm}

\noindent The trivial 1-point lattice, which is both terminal and initial and we write as $0$, is the unit for
$\biprod$. Such a structure $(\biprod, 0)$ where $\biprod$ acts as both a product and a coproduct is called a
\emph{biproduct} (\secref{biproducts}). The presence of a zero object in a Cartesian closed category $\cat{C}$
renders $\cat{C}$ trivial; if $0 \times X \iso X$ then $\Hom{\cat{C}}{X}{Y} \iso \Hom{\cat{C}}{0}{X
\Rightarrow Y} \iso 1$, and $\cat{C}$ has only a single object, up to isomorphism. Although the biproduct
structure rules out Cartesian closure, it will prove crucial for establishing a Cartesian closed setting in
\secref{higher-order}; first we develop a suitable categorical setting for first-order programs.
