\section{Related Work}
\label{sec:related-work}

\subsection{Stable Domain Theory}

Stable Domain Theory was originally proposed by \citet{berry79} as a refinement of domain theory aimed at
capturing the intensional behaviour of sequential programs, and elaborated on subsequently by \citet{berry82}
and \citet{amadio-curien}. Standard domain-theoretic models interpret programs as continuous functions,
preserving directed joins; Berry observed that this continuity condition alone is too permissive to model
sequentiality. Stability imposes additional constraints to reflect how functions preserve bounded meets of
approximants, effectively requiring that the evaluation of a function respect a specific computational order.
Though stable functions do not fully characterise sequentiality, because they admit $\mathrm{gustave}$-style
counterexamples (\exref{parallel-or}), they remain an appropriate notion for studying the sensitivity of a
program to partial data at a specific point.

Our use of Stable Domain Theory diverges from the traditional aim of modelling infinite or partial data,
however. Instead, we follow a line of work that uses partiality as a qualitative notion of approximation
suitable for provenance and program slicing (discussed in more detail in \secref{related-work:galois-slicing}
below). Paul Taylor’s characterisation of stable functions via local Galois connections on principle downsets
provides the semantic underpinning for the reverse maps used in Galois slicing~\cite{taylor99}. Our work
builds on these ideas by interpreting Galois slicing as a form of differentiable programming, using the
machinery of CHAD to present Galois slicing in a denotational style.

\subsection{Automatic Differentiation}

Automatic differentiation (AD), discussed in \secref{first-order:autodiff}, is the idea of computing
derivatives of functions expressed as programs by systematically applying the chain rule. The observation that
these derivative computations could be interleaved with the evaluation of the original program is due to
\citet{linnainmaa76}, who showed how the forward derivative $\pushf{f}_x$ of $f$ at a point $x$ could be
computed alongside $f(x)$ in a single pass, dramatically improving the efficiency of derivative evaluation
over symbolic or numerical differentiation. This insight became the foundation of forward-mode AD, which
underpins many optimisation and scientific computing tools, including JAX~\cite{jax2018github}.
\citet{griewank89} showed how the Wengert list, the linear record of assignments used in forward-mode to
compute derivatives efficiently, could be traversed in reverse to compute the pullback map. This two-pass
approach is the foundation of reverse-mode AD, and closely resembles implementations of Galois slicing
(\secref{related-work:galois-slicing} below) that record a trace during forward slicing for use in backward
slicing.

More recent approaches to automatic differentiation have emphasised semantic foundations. \citet{elliott18}
proposed a categorical model of AD that interprets programs as functions enriched with their derivatives,
giving a compositional account of differentiation based on duality and linear maps. Vákár and
collaborators~\cite{vakar22,nunes2023} developed the CHAD framework which inspired this paper, using
Grothendieck constructions over indexed categories to capture both values and their tangents in a
compositional semantic structure. These perspectives shed light on the categorical structure of AD and guide
the design of systems that generalise AD beyond real analysis, including the application to data provenance
and slicing explored in this paper.

\subsection{\GPS}
\label{sec:related-work:galois-slicing}

Galois slicing was introduced by \citet{perera12a} as an operational approach to program slicing for pure
functional programs, based on Galois connections between lattices of input and output approximations. A
connection to stable functions in relation to minimal slices for short-circuiting operations was alluded to
in~\citet{perera13}. Subsequent work extended the approach to languages with assignment and
exceptions~\cite{ricciotti17} and concurrent systems, applying Galois slicing to the
$\pi$-calculus~\cite{perera16d}. For the $\pi$-calculus the analysis shifted from functions to transition
relations, considering individual transitions $P \longrightarrow Q$ between configurations $P$ and $Q$ as
analogous to the edge between $x$ and $f(x)$ in the graph of $f$, and building Galois connections between
$\downset{P}$ and $\downset{Q}$. The main difference with the approach presented here is that the earlier work
also computes \emph{program slices}, using approximation lattices that represent partially erased programs; we
discuss this further in \secref{conclusion} below.

More recent work explored Galois slicing for interactive visualisations. \citet{perera22} presented an
approach where slicing operates over Boolean algebras rather than plain lattices. In this setting every Galois
connection $f \dashv g: A \to B$ has a conjugate $g^\circ \dashv f^\circ: B \to A$, where $f^\circ$ denotes
the De Morgan dual $\neg \comp f \comp \neg$~\cite{jonsson51}. The provenance analysis can then be composed
with its own conjugate to obtain a Galois connection which computes \emph{related outputs} (e.g., selecting a
region of a chart and observing the regions of other charts which share data dependencies). \citet{bond25}
revisited this approach using \emph{dynamic dependence graphs} to decouple the derivation of dependency
information from the analyses that make use of it, and observing that to compute the conjugate analysis one
can just use the opposite graph.

\subsection{Tangent Categories}

\emph{Tangent categories}, due originally to \citet{rosický84} and developed by \citet{cockett14,cockett18},
provide an abstract categorical framework for reasoning about differentiation, inspired by the structure of
the tangent bundle in differential geometry. In a tangent category, each object $X$ is equipped with a tangent
bundle $T(X)$, and each morphism $f: X \to Y$ has a corresponding differential map $T(f): TX \to TY$
satisfying axioms analogous to the chain rule and linearity of differentiation. Tangent categories generalise
Cartesian differential categories \cite{cdcs}, which model differentiation over Cartesian closed categories
using a syntactic derivative operator. The motivation behind tangent categories is to \roly{Bob to say
something here..}

\subsection{Lens Categories}

\cite{spivak19}
