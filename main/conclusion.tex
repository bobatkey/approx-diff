\section{Conclusion and Future Work}
\label{sec:conclusion}

\paragraph{Quantitative slicing and XAI}  Explainable AI (XAI) techniques like Gradient-weighted Class
Activation Mapping (Grad-CAM)~\cite{selvaraju20} use reverse-mode AD selectively to calculate \emph{heat maps}
(or \emph{saliency maps}) that highlight input regions contributing to a given classification or other
outcome. We would like to investigate quantitative approximation structures where $\top$ represents the
original input image and lower elements represent ``slices'' of the image where individual pixels have been
ablated to some degree (partly removed or blurred). This might allow for composing some of these techniques
with Galois slicing, for use in hybrid systems such as physical simulations with ML-based parameterisations.

\paragraph{More Approximation Domains.} The intervals example is
interesting, but is it useful, and are there more examples like this?
One route might be to follow \cite{edalat-heckmann98} and explore
whether metric spaces (which already provide a native notion of
approximation) can be embedded in $\Fam(\LatGal)$.

\paragraph{Alternative Higher-Order Models}

1. $\Fam(\PSh_{\CMon}(\LatGal))$

2. Concrete sheaves over $\Fam(\LatGal)$ analogous to Diffeological spaces?

\paragraph{Categorical Models of Differentation}

\paragraph{Recursion and Partiality.}
1. Despite using stable domain theory as our starting point, we have ignored

2. Conjecture that the category with $(X : \namedcat{Cpo}, \partial X : X \to \CLatGal)$, where $\CLatGal$ is the category of complete lattices and Galois connections is the right setting. Would need to investigate the connections with dI-domains, bidomains, and bistable bidomains \cite{laird07}.

Are bidomains \cite{berry79} useful? they have two orderings. See also
Laird's Bistable Biorders \cite{laird07}.

\paragraph{General Inductive and Coinductive Types}

Lists are the only recursive data type we provided in our source language, so important future work is
supporting general inductive and coinductive types. \citet{nunes2023} support automatic differentiation for
datatypes defined as the least or greatest fixed points of $\mu\nu$-polynomial functors; we could potentially
adopt a similar approach. Full inductive types would allow us to embed an interpreter for untyped lambda
calculus; combined with the CBN monadic translation described in \secref{cbn-translation} which uniformly inserts
approximation points, we should be able to obtain the program slicing behaviour of earlier \GPS work ``for
free''. Coinductive types (e.g.~streams) present additional challenges, especially for defining
join-preserving backward maps, but also open the door to slicing (finite prefixes of) infinite data sources,
with some likely relationship to the problem of dealing with partial or non-terminating computations.

\paragraph{Source-To-Source Translation Techniques}

% To formalise this, we'd need to... See also $\Fam(\PSh_{\CMon}(\namedcat{Syn}))$?

An interesting alternative to the denotational approach presented here, and to the trace-based approaches used
in earlier \GPS implementations, would be to develop a source-to-source transformation, in direct analogy with
the CHAD approach to automatic differentiation \cite{vakar22,nunes2023}. In their approach, forward and
reverse-mode AD are implemented as compositional transformations on source code, guided by a universal
property: they arise as the unique structure-preserving functors from the source language to a suitably
structured target language formalised as a Grothendieck construction. Adapting this to Galois slicing would
allow slicing to ``compiled in'', avoiding the need for a custom interpreter and potentially exposing
opportunities for optimisation.
