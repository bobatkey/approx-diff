\subsection{Stable Functions}
\label{sec:stable-functions}

Central to the concept of Galois slicing is the idea that
approximations of a value are a lattice, and that the functions
transporting approximations forwards and backwards form a Galois
connection between those lattices. We present a motivation for this
theory starting from the idea of qualitative information ordering from
Domain Theory. We argue that, with reference to differentiability,
monotone functions between certain partially ordered sets are
analogous to differentiable functions, and \emph{stable} functions
between those sets are analogous to functions with a reverse
derivative.

The stable function approach works, but mixes values and their
approximations into a single set. We use the families construction
over the category of lattices and Galois connections to separate
approximation from computation, and to provide a stepping stone to
executable models of Galois slicing.

\subsubsection{Domain Theory}

Domain theory is a method for giving denotational semantics to
programs that handle infinite data (i.e., functions,
streams). \emph{Domains} are special partially ordered sets where the
ordering denotes a relationship of qualitative information content: if
$x \sqsubseteq y$, then $y$ may contain more information than $x$. For
example, if $x$ and $y$ are functions, then $y$ may be defined at more
places in its domain than $x$.

Domains are typically closed under least upper bounds (\emph{lubs}) of
directed sets, meaning that any collection of elements that is
internally consistent has a ``completion'' that contains all the
information covered by the set. These directed lubs are used to give
semantics to recursive programs in terms of their finite
approximations.

Programs themselves are interpreted as monotone functions that
preserve directed lubs. The latter property is called
continuity. Monoticity captures the idea that if the input gets more
defined, then the output can get more defined. Continuity intuitively
expresses the idea that a function interpreting a program cannot
``look at all the approximations'' when determining the output, which
corresponds to the intuitive idea that a computable function cannot
look at a non-finite amount of input to produce an output.

For the purposes of Galois slicing, we are not interested in using
approximations to model computation on infinite objects, but rather to
use them for the related task of revealing how programs explore their
inputs for provenance tracking. Therefore, we start by only
considering certain partially ordered sets and monotone functions
between them.

\subsubsection{Forwards Slicing}

We now set up an analogy between certain partial orders with monotone
functions and manifolds and smooth functions.

In a partially ordered set $X$, for any $x \in X$ the set of elements
below $x$, $\downset{x} = \{ x' \mid x' \sqsubseteq x \}$, is itself a
partially ordered set. These approximations of $x$ we will think of as
``derivatives'' of $x$, and the whole set $\downset{x}$ as the
``tangent space''. Tangent spaces are vector spaces, since they are
linear approximations to curves at that point. In the partially
ordered setting, we take elements of $\downset{x}$ to be
approximations of processes defined at $x$. As we can add tangents, we
assume we can take meets of approximations in $\downset{x}$:

\begin{definition}
  A \emph{meet approximation space} is a partially ordered set $X$
  where every for every $x \in X$, $\downset{x}$ is a meet
  semilattice, with $x$ as the top element.
\end{definition}

Smooth functions have a ``pushforward'' derivative that takes tangents
at a point $x$ to tangents at the point $f(x)$. In the partially
ordered setting, we require that the restriction of a monotone
function $f$ to each $\downset{x}$ preserves meets:

\begin{definition}
  A \emph{morphism of meet approximation spaces} $f : X \to Y$ is a
  monotone function such that for all $x \in X$, the restriction
  $f_x : \downset{x} \to \downset{f(x)}$ preserves meets.
\end{definition}

\begin{lemma}
  Morphisms of meet approximation spaces are closed under identities
  and composition, forming a category. FIXME: with products?
  functions? sums?
\end{lemma}

\begin{example}
  FIXME: various forms of OR:
  \begin{itemize}
  \item strict and left-short-circuiting
  \item parallel or
  \item gustave
  \end{itemize}
\end{example}

\begin{example}
  An example that preserves meets, but isn't stable (from Amadio and
  Curien just before Lemma 12.2.3, originally due to Berry): Define
  $f : D \to \{\bot, \top\}$, where:
  \begin{displaymath}
    D = \bot \sqsubseteq \cdots \sqsubseteq n \sqsubseteq \cdots \sqsubseteq 1 \sqsubseteq 0
  \end{displaymath}
  as $f(\bot) = \bot$ and $f(n) = \top$. This is monotone, and
  preserves meets in every $\downset{x}$. However, there is no
  ``best'' (i.e., least) input that gives us any finite output. To
  rectify this, we will further assume that our functions are stable.
\end{example}

\subsubsection{Backwards Slicing}

Stable functions are an antecedent of Galois slicing that arose in
domain theory as an attempt to capture the idea that any function
describing a computational process must explore its input in a way
that allows identification of minimal parts of the input that are
needed for chosen approximations of the output.

Stability was invented by Berry \cite{berry79} in an attempt to capture
sequentiality, and were also instrumental in the discovery of Linear
Logic via Coherence Spaces \cite{girard}. A textbook description of
stable functions in the context of domain theory is given by Amadio
and Curien \cite{amadio-curien} (Chapter 12). Here, we are not
concerned with completeness properties considered in domain theory, so
we start with only partially ordered sets. Stable functions can be
defined as a certain subset of the set of monotone functions between
two partially ordered sets:

\begin{definition}
  Let $f : X \to Y$ be a monotone function between posets $X$ and
  $Y$. The function $f$ is \emph{stable} if for all $x \in X$ and
  $y \leq f(x)$:
  \begin{enumerate}
  \item (\textsc{Existence}) there exists an $x_0 \leq x$ such that $y \leq f(x_0)$, and
  \item (\textsc{Minimality}) for any $x'_0 \leq x$ such that $y \leq f(x'_0)$ then
    $x_0 \leq x'_0$ .
  \end{enumerate}
\end{definition}

\begin{lemma}
  Stable functions are closed under identities and composition.
\end{lemma}

\begin{example}[Stability reveals intensional information]
  To see how stability works, consider the following examples of the
  OR operation on the lifted booleans $\mathbb{B}_\bot$. Two functions
  that are stable are the strict and left-short-circuiting
  ORs\footnote{The clauses in these examples are shorthand for the
    graph of the function. They are not to be understood as pattern
    matching clauses in a language like Haskell, where it is not
    possible to match on $\bot$.}:
  \begin{displaymath}
    \begin{array}[t]{l@{(}l@{,~}l@{)~}c@{~}l}
      \mathrm{strictOr}&\mathsf{tt}&\mathsf{tt}&=&\mathsf{tt} \\
      \mathrm{strictOr}&\mathsf{tt}&\mathsf{ff}&=&\mathsf{tt} \\
      \mathrm{strictOr}&\mathsf{ff}&\mathsf{tt}&=&\mathsf{tt} \\
      \mathrm{strictOr}&\mathsf{ff}&\mathsf{ff}&=&\mathsf{ff} \\
      \mathrm{strictOr}&\bot&\_&=&\bot \\
      \mathrm{strictOr}&\_&\bot&=&\bot \\
    \end{array}
    \qquad
    \begin{array}[t]{l@{(}l@{,~}l@{)~}c@{~}l}
      \mathrm{shortCircuitOR}&\mathsf{tt}&\_&=&\mathsf{tt} \\
      \mathsf{shortCircuitOR}&\mathsf{ff}&x&=&x \\
      \mathsf{shortCircuitOR}&\bot&\_& =& \bot
    \end{array}
  \end{displaymath}
  The function $\mathrm{strictOr}$ is stable. For example, for the
  input-output pair $(\mathsf{tt},\mathsf{ff}), \mathsf{tt}$, the
  minimal input that gives this output is exactly
  $(\mathsf{tt}, \mathsf{ff})$. If we take the approximation
  $\bot \leq \mathsf{tt}$ of the output, then the corresponding
  minimal input is $(\bot, \bot)$. The function
  $\mathrm{shortCircuitOR}$ is also stable. For the input-output pair
  $(\mathsf{tt},\mathsf{ff}),\mathsf{tt}$, the minimal input that
  gives this input is $(\mathsf{tt},\bot)$, indicating that the
  presence of $\mathsf{ff}$ in the second argument was not necessary
  to produce this output. As with $\mathrm{strictOr}$, the minimal
  input required to produce the output $\bot \leq \mathsf{tt}$ is
  again $(\bot,\bot)$.

  The fact that these two functions's stability witnesses reveal
  information about how they depend on their input is what we will
  exploit in order to use the idea of stability for slicing.
\end{example}

\begin{example}[Functions that are not stable]
  A function that is not stable is Plotkin's Parallel OR \cite{lcf77},
  which short-circuits in both arguments, returning $\mathsf{tt}$ if
  either argment is $\mathsf{tt}$, even if the other argument is not
  defined:
  \begin{displaymath}
    \begin{array}{l@{(}l@{,~}l@{)~}c@{~}l}
      \mathrm{parallelOR}&\mathsf{tt}&\_&=&\mathsf{tt} \\
      \mathrm{parallelOR}&\_&\mathsf{tt}&=&\mathsf{tt} \\
      \mathsf{parallelOR}&\mathsf{ff}&\mathsf{ff}&=&\mathsf{ff} \\
      \mathsf{parallelOR}&\bot&\bot&=&\bot
    \end{array}
  \end{displaymath}
  For the input-output pair $(\mathsf{tt},\mathsf{tt}),\mathsf{tt}$,
  there is no one minimal input that produces this output. We have
  both $\mathrm{parallelOR}(\mathsf{tt},\bot) = \mathsf{tt}$ and
  $\mathrm{parallelOR}(\bot,\mathsf{tt}) = \mathsf{tt}$, which are
  incomparable and their greatest lower bound $(\bot,\bot)$ gives the
  output $\bot$.

  Parallel OR is famous because it is not \emph{sequential}, meaning
  intuitively that it cannot be implemented without running the two
  arguments in parallel to see if one of them returns
  $\mathsf{tt}$. That fact that it exists in the standard domain
  theoretic semantics of PCF means that this semantics is not fully
  abstract. Since Parallel OR is not stable, one might hope that
  stability is enough to capture sequentiality, and hence potentially
  give a fully abstract model of PCF. However, the following ternary
  function $\mathbb{B}_\bot^3 \to \{\top,\bot\}$ is stable but admits
  no sequential implementation that fixes an order that the arguments
  are examined in:
  \begin{displaymath}
    \begin{array}{l@{(}l@{,~}l@{,~}l@{)~}c@{~}l}
      \mathrm{gustave}&\mathsf{tt}&\mathsf{ff}&\_&=&\top \\
      \mathrm{gustave}&\mathsf{ff}&\_&\mathsf{tt}&=&\top \\
      \mathrm{gustave}&\_&\mathsf{tt}&\mathsf{ff}&=&\top \\
      \mathrm{gustave}&\_&\_&\_&=&\bot
    \end{array}
  \end{displaymath}
  Despite there being no one minimal input that achieves the output
  $\top$, each of the minimal inputs that can achieve this output are
  pairwise incomparable, so for each specific input that gets output
  $\top$ there is a unique minimal input that achieves it (listed in
  the first three lines of the definition).

  In terms of program slicing, however, the $\mathrm{gustave}$
  function does not present a problem. For any particular run (i.e.,
  input-output pair) of the program, there is an unambiguous minimal
  input that achieves the output, no matter that it was not achieved
  by a sequential processing of the input.
\end{example}

The definition of stability has a nice operational meaning, but seems
a little ad-hoc. We can rephrase stability in terms of Galois
connections / adjunctions between principal downsets / slices of the
partial orders. The alternative presentation also has the advantage
that it explicitly defines the stability witness as ``backwards''
function from approximations of the output to approximations of the
input.


\begin{definition}
  For a poset $X$ and $x \in X$, the \emph{principal
    downset of $x$} is $\downset{x} = \{ x' \in X \mid x' \leq x \}$.
\end{definition}

\begin{lemma}
  If $f : X \to Y$ is monotonic, then for all $x \in X$, the
  restriction of $f$ to $\downset{x}$ is a monotone function
  $f_x : \downset{x} \to \downset{f(x)}$.
\end{lemma}

\begin{proof}
  $f_x$ is well defined: for any $x' \leq x$,
  $f_x(x') = f(x') \leq f(x)$ by monotonicity, so
  $f_x(x') \in \downset{f(x)}$. The function $f_x$ is monotone because
  $f$ is.
\end{proof}

\begin{lemma}
  A monotone function $f : X \to Y$ is stable if and only if for all
  $x \in X$, the restriction of $f_x : \downset{x} \to \downset{f(x)}$
  has a left adjoint.
\end{lemma}

\begin{proof}
  If $f$ is stable, then define a left adjoint
  $g_x : \downset{f(x)} \to \downset{x}$ by setting $g_x(y)$ to be the
  minimal $x_0$ required by stability. This is monotone: if
  $y \leq y'$, then we know that $y \leq y' \leq f(g_x(y'))$ by
  definition of $g_x$, so $g_x(y) \leq g_x(y')$ by minimality of
  $g_x(y)$. For the adjointness, let $x' \leq x$ and $y \leq
  f(x)$. Then if $g_x(y) \leq x'$, we have
  $y \leq f(g_x(y)) \leq f(x')$ by monotonicity of $f$ and the first
  part of stability. In the other direction, if we have
  $y \leq f(x')$, then by uniqueness we have $g_x(y) \leq x'$.

  If, for every $x$, $f_x$ has a left adjoint $g_x$, then for any
  $x', y$ we have $y \leq f_x(x') \Leftrightarrow g_x(y) \leq x'$. So
  $g_x(y)$ is the element that satisfies $y \leq f(g_x(y))$, and it is
  minimal since if $y \leq f_x(x'_0)$ then $g_x(y) \leq x'_0$.
\end{proof}

For what follows\footnote{Need a better way of motivating this.}, it
will be useful for the principal downsets to be bounded lattices, so
that we are guaranteed to have meets and joints of approximations of
points. Note that the principal downsets always have a top element
(the original element), but now we are also requiring a bottom
element, as well as finite meets and joins.

FIXME: is this a good name? Maybe just $\mathbf{Stable}$ or something
like that?

FIXME: if $x \leq x'$ then $\downset{x} \subseteq \downset{x'}$ and I
assume that the inclusion preserves lattice structure?

\begin{definition}
  An \emph{approximation set} is a partial order such that every
  principal downset $\downset{x}$ is a bounded lattice.

  A morphism of approxmation sets is monotone function whose
  restriction to each slice has a left adjoint.
\end{definition}

Note that, by standard properties of Galois connections/adjoints, the
pairs $g_x \vdash f_x$ preserve the finite joins and meets respectively.

\begin{proposition}
  Approximation sets and their morphisms form a category.
\end{proposition}

FIXME: what properties does this category have? I think it has finite
products, and probably finite coproducts?

FIXME: there is a full and faithful functor from approximation sets to
$\Fam(\LatGal)$.
